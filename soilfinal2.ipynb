{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKUOkFaENqCUfKtegsAqoC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushiiel22bds0390/opendatasets/blob/master/soilfinal2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1vXjbCIHSCo",
        "outputId": "bac319aa-4b87-462a-a007-6242ba1ffb61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/68.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/68.6 kB\u001b[0m \u001b[31m662.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m776.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install jovian --upgrade --quiet\n",
        "!pip install opendatasets --upgrade --quiet\n",
        "import opendatasets as od\n",
        "dataset_url='https://www.kaggle.com/datasets/jayaprakashpondy/soil-image-dataset'\n",
        "od.download(dataset_url)\n",
        "data_dir1='/content/soil-image-dataset'\n",
        "import os\n",
        "os.listdir(data_dir1)\n",
        "for cls in os.listdir(data_dir1):\n",
        "  print(cls,':',len(os.listdir(data_dir1+'/'+cls)))\n",
        "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "from torchvision.datasets import ImageFolder\n",
        "datasets=ImageFolder(data_dir1)\n",
        "len(datasets)\n",
        "datasets[0]\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "img,label=datasets[0]\n",
        "plt.imshow(img)\n",
        "import torchvision.transforms as tt\n",
        "import os\n",
        "import torchvision.transforms as tt\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "# Set the path to your dataset directory\n",
        "data_dir = \"/content/soil-image-dataset\"\n",
        "\n",
        "# List all files in the dataset directory\n",
        "file_list = os.listdir(data_dir)\n",
        "\n",
        "# Filter files to include only those with the \".jpg\" extension\n",
        "jpg_files = [file for file in file_list if file.lower().endswith(\".jpg\")]\n",
        "\n",
        "# Create a new directory to store the updated images\n",
        "new_data_dir = \"/content/soil-image-dataset\"\n",
        "os.makedirs(new_data_dir, exist_ok=True)\n",
        "\n",
        "# Move or copy the \".jpg\" files to the new directory\n",
        "for jpg_file in jpg_files:\n",
        "    source_path = os.path.join(data_dir, jpg_file)\n",
        "    target_path = os.path.join(new_data_dir, jpg_file)\n",
        "    shutil.copy(source_path, target_path)\n",
        "\n",
        "# Create the ImageFolder dataset\n",
        "dataset = ImageFolder(new_data_dir, tt.Compose([tt.Resize(64), tt.RandomCrop(64), tt.ToTensor()]))\n",
        "img,label=dataset[94]\n",
        "plt.imshow(img.permute((1,2,0)))\n",
        "val_pct=0.2\n",
        "val_size=int(val_pct*len(dataset))\n",
        "train_size=len(dataset)-val_size\n",
        "train_size,val_size\n",
        "from torch.utils.data import random_split\n",
        "train_ds,valid_ds=random_split(dataset,[train_size,val_size])\n",
        "len(train_ds),len(valid_ds)\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size=64\n",
        "train_dl = DataLoader(train_ds,\n",
        "                      batch_size,\n",
        "                      shuffle=True,\n",
        "                      num_workers=4,\n",
        "                      pin_memory=True)\n",
        "valid_dl = DataLoader(valid_ds,\n",
        "                    batch_size*2,\n",
        "                    num_workers=4,\n",
        "                    pin_memory=True)\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "def show_batch(dl):\n",
        "    for images, labels in dl:\n",
        "        fig, ax = plt.subplots(figsize=(12, 6))\n",
        "        ax.set_xticks([]); ax.set_yticks([])\n",
        "        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
        "        break\n",
        "show_batch(train_dl)\n",
        "import torch\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "\n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl:\n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "torch.cuda.is_available()\n",
        "device=get_default_device()\n",
        "device\n",
        "img,label=dataset[0]\n",
        "img.device\n",
        "img_cpu=to_device(img,device)\n",
        "img_cpu.device\n",
        "train_dl = DeviceDataLoader(train_dl, device)\n",
        "valid_dl = DeviceDataLoader(valid_dl, device)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch\n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "\n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['train_loss'], result['val_loss'], result['val_acc']))\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase\n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history\n",
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "              nn.BatchNorm2d(out_channels),\n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet9(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        #78*3*64*64\n",
        "        self.conv1 = conv_block(in_channels, 64)#78*64*64*64\n",
        "        self.conv2 = conv_block(64, 128, pool=True)#78*128*32*32\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "\n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "\n",
        "        self.classifier = nn.Sequential(nn.AdaptiveMaxPool2d(1),\n",
        "                                        nn.Flatten(),\n",
        "                                        nn.Dropout(0.5),\n",
        "                                        nn.Linear(512, num_classes))\n",
        "\n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "model=to_device(ResNet9(3,len(dataset.classes)),device)\n",
        "model\n",
        "model.conv1[0].weight.device\n",
        "for batch in train_dl:\n",
        "  images,labels=batch\n",
        "  print('image.shape',images.shape)\n",
        "  print('images.device',images.device)\n",
        "  preds=model(images)\n",
        "  print('preds.shape',preds.shape)\n",
        "  break\n",
        "history = [evaluate(model, valid_dl)]\n",
        "history\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "\n",
        "def fit(epochs, learning_rate, model, train_dl, valid_dl, optimizer_fn):\n",
        "    optimizer = optimizer_fn(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    history = {'train_loss': [], 'train_acc': [], 'valid_loss': [], 'valid_acc': []}\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "        for inputs, labels in train_dl:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = total_loss / len(train_dl)\n",
        "        train_acc = correct / total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in valid_dl:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        valid_loss = total_loss / len(valid_dl)\n",
        "        valid_acc = correct / total\n",
        "\n",
        "        # Store the metrics in history\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['valid_loss'].append(valid_loss)\n",
        "        history['valid_acc'].append(valid_acc)\n",
        "\n",
        "        # Print the metrics\n",
        "        print(f'Epoch {epoch + 1}/{epochs}, '\n",
        "              f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
        "              f'Valid Loss: {valid_loss:.4f}, Valid Acc: {valid_acc:.4f}')\n",
        "\n",
        "    return history\n",
        "\n",
        "# Assuming your model, train_dl, and valid_dl are defined earlier\n",
        "history = fit(2, 0.01, model, train_dl, valid_dl, torch.optim.Adam)"
      ]
    }
  ]
}